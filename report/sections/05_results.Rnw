% !Rnw root = ../report.Rnw

\section*{Results}

\subsection*{Completion Rates}

<<coefficients, results=tex, echo=FALSE>>=
# load data and library
options(warn = -1)
library(xtable)
library(png)
library(grid)
library(Matrix)
library(methods)
library(ggplot2)
library(reshape2)

# load data in our working environment 
load('../data/ols_results_completion.RData')
load('../data/ridge_results_completion.RData')
load('../data/lasso_results_completion.RData')
load('../data/pcr_results_completion.RData')
load('../data/pls_results_completion.RData')
load('../data/ols_results_income.RData')
load('../data/ridge_results_income.RData')
load('../data/lasso_results_income.RData')
load('../data/pcr_results_income.RData')
load('../data/pls_results_income.RData')


# load our functions
source("../code/functions/function_mse.R")
@

From our exploratory analysis we find several interesting relationships between completion rates and several predictors. Below are some scatterplots exhibiting these relationships. From the below figures we see that first generation status is negatively correlated with completion, cost of attendance is positively correlated, and percentage of student body as black seems to have no correlation.

\begin{figure}[!hb]
  \centering
    \includegraphics[width=55mm]{../images/firstgen_completion.png}
      \caption{Plot of Completion Rates against First Generation Status}
\end{figure}

\vspace{40mm}

\begin{figure}[!hb]
  \centering
    \includegraphics[width=65mm]{../images/costattend_completion.png}
      \caption{Plot of Completion Rates against Cost of Attendance}
\end{figure}

\begin{figure}[!hb]
  \centering
    \includegraphics[width=65mm]{../images/black_completion_all.png}
      \caption{Plot of Completion Rates against Percentage of Black Population}
\end{figure}


Now let's look at our predictive models. We obtain the test mean squared errors for every predictive model from our analysis. Below is the table of MSEs for each model.

\vspace{40mm}

<<coefficients, results=tex, echo=FALSE>>=
# Create test mse dataframe

table_mse <- data.frame("Ridge" = ridge_test_MSE_c, "Lasso" = lasso_test_MSE_c,
                        "PCR" = pcr_test_MSE_c, "PLSR" = pls_test_MSE_c)
rownames(table_mse) <- "MSE Value"

# Use xtable to display our test mse dataframe
xtable_mse <- xtable(table_mse, caption = 'Test MSE for All Methods', 
                     digits = c(0, 3, 3, 3, 3))
print(xtable_mse, comment=FALSE, type = "latex", caption.placement = 'top')
@

Table 3 has only one row (Test MSE value) and four columns (one column per regression methods: ridge, lasso, pcr, and plsr).

From Table 3, the result shows that the model with lowest test Mean Square Error is Lasso Regression, which means that lasso regression actually has the best performance when we test the prediction against the true value in testing set. Thus we use the results from lasso regression as our best model and official coefficients for the regression.


<<coefficients, results=tex, echo=FALSE>>=
# Extract coefficients and convert them into vectors
ols_coef_vector <- ols_coef_c[2:nrow(ols_coef_c)]
ridge_coef_vector <- unlist(ridge_coef_c)[2:nrow(ols_coef_c)]
lasso_coef_vector <- unlist(lasso_coef_c)[2:15]
pcr_coef_vector <- pcr_coef_c[1:14]
plsr_coef_vector <- pls_coef_c[1:14]

# Create a table of regression coefficients for all methods
table_coef <- data.frame("OLS" = ols_coef_vector, "Ridge" = ridge_coef_vector, 
                         "Lasso" = lasso_coef_vector, "PCR" = pcr_coef_vector,
                         "PLSR" = plsr_coef_vector)
rownames(table_coef) <- rownames(ridge_coef_c)[2:nrow(ols_coef_c)]

@


The following table contains the regression coefficient results for completion rates. We include the results from all methods for comparison, with lasso regression selected as our official results.

<<coefficients, results=tex, echo=FALSE>>=
# Use xtable to display our coefficients dataframe
xtable_coef <- xtable(table_coef, caption = 'Regression Coefficients for All Methods',
                      digits = c(0, 3, 3, 3, 3, 3))
print(xtable_coef, comment=FALSE, type = "latex", caption.placement = 'top')
@


From Table 4, the results show that regression coefficients for Ridge, Lasso, PCR, and PLSR are approximately closed to each other's value but are slightly different compared to OLS - our benchmark. 

Not surprisingly, we have seen that some coefficients in lasso regression are zero because lasso regression allows coefficients to be zero to minimize the regression penalty.

From our results we see that coming from a low income bracket family, having federal loans, and being a first generation student have a strong negative relationship with income. Interestingly, race does not seem to have a large influence on completion rates after controlling for other factors. If anything, an increased percentage of black population tends to increase completion rates. Cost of attendance and SAT scores heavily influence completion rates positively as well, possibly because more prestigious schools are more expensive with better students so they have better graduation rates.

\subsection*{Income}

From our exploratory analysis we also find some interesting relationships between income and several predictors. Below are some scatterplots exhibiting these relationships. From the below figures we see that, like with completion rates, first generation status is negatively correlated with income 10 years after graduation, while cost of attendance is positively correlated. Also, percentage of student body as black seems to have no correlation with post-graduate income.

\vspace{10mm}

\begin{figure}[!hb]
  \centering
    \includegraphics[width=80mm]{../images/firstgen_earnings.png}
      \caption{Plot of Earnings against First Generation Status}
\end{figure}

\vspace{105mm}

\begin{figure}[!hb]
  \centering
    \includegraphics[width=80mm]{../images/costattend_earnings.png}
      \caption{Plot of Earnings against Cost of Attendance}
\end{figure}

\begin{figure}[!hb]
  \centering
    \includegraphics[width=80mm]{../images/black_earnings_all.png}
      \caption{Plot of Earnings against Percentage of Black Population}
\end{figure}

\vspace{20mm}

Now, we look the MSE of each model, this time with post-graduate income as our regressor.

<<coefficients, results=tex, echo=FALSE>>=
# Extract coefficients and convert them into vectors

table_mse <- data.frame("Ridge" = ridge_test_MSE_i, "Lasso" = lasso_test_MSE_i,
                        "PCR" = pcr_test_MSE_i, "PLSR" = pls_test_MSE_i)
rownames(table_mse) <- "MSE Value"

# Use xtable to display our test mse dataframe
xtable_mse <- xtable(table_mse, caption = 'Test MSE for All Methods', 
                     digits = c(0, 3, 3, 3, 3))
print(xtable_mse, comment=FALSE, type = "latex", caption.placement = 'top')
@

Table 5 is similar to Table 1, except the MSEs are overall larger than with completion rates as our outcome, meaning that the regression line fits the data somewhat better for completion rates.

From Table 5, the results shows that the model with lowest test Mean Square Error is also Lasso Regression. Thus we use the results from lasso regression as our best model and official coefficients as well.


<<coefficients, results=tex, echo=FALSE>>=
#Extract and convert to vectors
ols_coef_vector <- ols_coef_i[2:nrow(ols_coef_i)]
ridge_coef_vector <- unlist(ridge_coef_i)[2:nrow(ols_coef_i)]
lasso_coef_vector <- unlist(lasso_coef_i)[2:15]
pcr_coef_vector <- pcr_coef_i[1:14]
plsr_coef_vector <- pls_coef_i[1:14]

# Create a table of regression coefficients for all methods
table_coef <- data.frame("OLS" = ols_coef_vector, "Ridge" = ridge_coef_vector, 
                         "Lasso" = lasso_coef_vector, "PCR" = pcr_coef_vector,
                         "PLSR" = plsr_coef_vector)
rownames(table_coef) <- rownames(ridge_coef_i)[2:nrow(ols_coef_i)]

@

The following table contains the regression coefficient results. We include the results from all methods for comparison, with lasso regression selected as our official results.

<<coefficients, results=tex, echo=FALSE>>=
# Use xtable to display our coefficients dataframe
xtable_coef <- xtable(table_coef, caption = 'Regression Coefficients for All Methods',
                      digits = c(0, 3, 3, 3, 3, 3))
print(xtable_coef, comment=FALSE, type = "latex", caption.placement = 'top')
@


From these results we learn that coming from a low income bracket and having federal loans are negatively associated with post-graduate income. Black and Hispanic population do not affect income, rather increased percentage of Whites has a negative effect while increased percentage of Asians has a positive effect. From this we learn that underrepresented races in universities do not affect post-graduate income after controlling for other variables. First generation status, cost of attendance, and SAT scores have a positive relationship with income. The last two may be expected for the same reason as the positive effect on completion rate, but the coefficient for first generation status may be suprising.


